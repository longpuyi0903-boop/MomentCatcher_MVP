import { useEffect, useRef, useState } from 'react'

/**
 * BGMç®¡ç†å™¨Hook
 * åŠŸèƒ½ï¼š
 * 1. éšæœºé€‰æ‹©å¹¶æ’­æ”¾BGM
 * 2. è‡ªåŠ¨å¾ªçŽ¯æ’­æ”¾
 * 3. éŸ³é‡æ·¡å…¥ï¼ˆ3ç§’ï¼‰
 * 4. å½•éŸ³/è¯­éŸ³æ’­æ”¾æ—¶éŸ³é‡é™åˆ°30%
 */
export const useBGM = (isAppReady, isRecording, isVoicePlaying) => {
  const audioContextRef = useRef(null)
  const gainNodeRef = useRef(null)
  const sourceRef = useRef(null)
  const audioBufferRef = useRef(null)
  const [currentBGM, setCurrentBGM] = useState(null)
  const isPlayingRef = useRef(false)
  const fadeInTimeoutRef = useRef(null)
  
  // BGMæ–‡ä»¶åˆ—è¡¨ï¼ˆéœ€è¦æ‰‹åŠ¨ç»´æŠ¤ï¼Œæ·»åŠ æ–°BGMæ—¶æ›´æ–°æ­¤åˆ—è¡¨ï¼‰
  const bgmFiles = [
    'Hans Zimmer - Interstellar - Main Theme (Piano Version)  Sheet Music.mp3'
    // åŽç»­æ·»åŠ æ›´å¤šBGMæ—¶ï¼Œåœ¨è¿™é‡Œæ·»åŠ æ–‡ä»¶å
  ]
  
  // éŸ³é‡å¸¸é‡
  const FULL_VOLUME = 0.6 // æ­£å¸¸éŸ³é‡ï¼ˆ60%ï¼‰
  const LOW_VOLUME = 0.18 // é™ä½ŽåŽçš„éŸ³é‡ï¼ˆ30% of 60%ï¼‰
  const FADE_IN_DURATION = 3000 // æ·¡å…¥æ—¶é•¿ï¼ˆ3ç§’ï¼‰
  
  // åˆå§‹åŒ–AudioContextï¼ˆå»¶è¿Ÿåˆ°éœ€è¦æ—¶åˆ›å»ºï¼Œé¿å…æµè§ˆå™¨é™åˆ¶ï¼‰
  const initAudioContext = () => {
    if (!audioContextRef.current) {
      try {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
        gainNodeRef.current = audioContextRef.current.createGain()
        gainNodeRef.current.connect(audioContextRef.current.destination)
        gainNodeRef.current.gain.value = 0 // åˆå§‹éŸ³é‡ä¸º0
        console.log('ðŸŽµ AudioContextåˆå§‹åŒ–æˆåŠŸ')
        
        // ã€æµ‹è¯•ä¼˜åŒ–ã€‘ç§»åŠ¨ç«¯ï¼šç«‹å³å°è¯•æ¢å¤AudioContextï¼ˆéœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
        if (audioContextRef.current.state === 'suspended') {
          // å°è¯•æ¢å¤ï¼ˆå¯èƒ½éœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
          audioContextRef.current.resume().then(() => {
            console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¼˜åŒ–] AudioContextå·²æ¢å¤')
          }).catch(err => {
            console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¼˜åŒ–] AudioContextæ¢å¤å¤±è´¥ï¼Œéœ€è¦ç”¨æˆ·äº¤äº’:', err)
          })
        }
      } catch (error) {
        console.error('âŒ AudioContextåˆå§‹åŒ–å¤±è´¥:', error)
      }
    } else if (audioContextRef.current.state === 'suspended') {
      // å¦‚æžœAudioContextè¢«æš‚åœï¼Œå°è¯•æ¢å¤
      audioContextRef.current.resume().then(() => {
        console.log('ðŸŽµ AudioContextå·²æ¢å¤')
      }).catch(err => {
        console.warn('âš ï¸ AudioContextæ¢å¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç”¨æˆ·äº¤äº’:', err)
      })
    }
  }
  
  useEffect(() => {
    return () => {
      // æ¸…ç†èµ„æº
      if (fadeInTimeoutRef.current) {
        clearTimeout(fadeInTimeoutRef.current)
      }
      if (sourceRef.current) {
        try {
          sourceRef.current.stop()
        } catch (e) {
          // å¿½ç•¥é”™è¯¯
        }
        sourceRef.current = null
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
    }
  }, [])
  
  // éšæœºé€‰æ‹©BGM
  const selectRandomBGM = () => {
    if (bgmFiles.length === 0) return null
    const randomIndex = Math.floor(Math.random() * bgmFiles.length)
    // ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒViteä¼šè‡ªåŠ¨å¤„ç†publicç›®å½•
    return `/bgm/${bgmFiles[randomIndex]}`
  }
  
  // åŠ è½½å¹¶æ’­æ”¾BGM
  const loadAndPlayBGM = async (bgmPath) => {
    try {
      // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
      initAudioContext()
      const audioContext = audioContextRef.current
      if (!audioContext) {
        console.error('âŒ AudioContextæœªåˆå§‹åŒ–')
        return
      }
      
      // å¦‚æžœå·²ç»æœ‰éŸ³é¢‘åœ¨æ’­æ”¾ï¼Œå…ˆåœæ­¢
      if (sourceRef.current) {
        try {
          sourceRef.current.stop()
        } catch (e) {
          // å¿½ç•¥é”™è¯¯
        }
        sourceRef.current = null
      }
      
      // åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆURLç¼–ç å¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
      const encodedPath = encodeURI(bgmPath)
      console.log('ðŸŽµ åŠ è½½BGM:', encodedPath)
      const response = await fetch(encodedPath)
      if (!response.ok) {
        throw new Error(`BGMåŠ è½½å¤±è´¥: ${response.status} ${response.statusText}`)
      }
      const arrayBuffer = await response.arrayBuffer()
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
      audioBufferRef.current = audioBuffer
      
      // åˆ›å»ºéŸ³é¢‘æº
      const source = audioContext.createBufferSource()
      source.buffer = audioBuffer
      source.loop = true // å¾ªçŽ¯æ’­æ”¾
      source.connect(gainNodeRef.current)
      
      sourceRef.current = source
      
      // å¼€å§‹æ’­æ”¾
      source.start(0)
      isPlayingRef.current = true
      
      // éŸ³é‡æ·¡å…¥
      const gainNode = gainNodeRef.current
      const currentTime = audioContext.currentTime
      const targetVolume = isRecording || isVoicePlaying ? LOW_VOLUME : FULL_VOLUME
      
      gainNode.gain.cancelScheduledValues(currentTime)
      gainNode.gain.setValueAtTime(0, currentTime)
      gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + FADE_IN_DURATION / 1000)
      
      console.log('ðŸŽµ BGMå¼€å§‹æ’­æ”¾:', bgmPath)
    } catch (error) {
      console.error('âŒ BGMåŠ è½½å¤±è´¥:', error)
    }
  }
  
  // å½“åº”ç”¨å‡†å¤‡å°±ç»ªæ—¶ï¼Œéšæœºé€‰æ‹©å¹¶æ’­æ”¾BGM
  useEffect(() => {
    if (isAppReady && !currentBGM && !isPlayingRef.current) {
      const bgmPath = selectRandomBGM()
      if (bgmPath) {
        setCurrentBGM(bgmPath)
        
        // ã€æµ‹è¯•ä¼˜åŒ–ã€‘ç§»åŠ¨ç«¯ï¼šå»¶è¿ŸåŠ è½½BGMï¼Œç¡®ä¿AudioContextå·²åˆå§‹åŒ–
        // ç§»åŠ¨ç«¯æµè§ˆå™¨éœ€è¦ç”¨æˆ·äº¤äº’æ‰èƒ½æ’­æ”¾éŸ³é¢‘ï¼Œæ‰€ä»¥å»¶è¿Ÿä¸€ç‚¹
        const delay = /Mobile|Android|iPhone|iPad/i.test(navigator.userAgent) ? 500 : 0
        setTimeout(() => {
          loadAndPlayBGM(bgmPath)
        }, delay)
      }
    }
  }, [isAppReady, currentBGM])
  
  // ã€æµ‹è¯•ä¼˜åŒ–ã€‘ç§»åŠ¨ç«¯ï¼šç›‘å¬ç”¨æˆ·äº¤äº’ï¼Œæ¢å¤AudioContext
  useEffect(() => {
    if (!isAppReady) return
    
    const handleUserInteraction = () => {
      if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
        audioContextRef.current.resume().then(() => {
          console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¼˜åŒ–] ç”¨æˆ·äº¤äº’åŽAudioContextå·²æ¢å¤')
          // å¦‚æžœBGMè¿˜æ²¡æ’­æ”¾ï¼Œå°è¯•æ’­æ”¾
          if (!isPlayingRef.current && currentBGM) {
            loadAndPlayBGM(currentBGM)
          }
        }).catch(err => {
          console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¼˜åŒ–] æ¢å¤AudioContextå¤±è´¥:', err)
        })
      }
    }
    
    // ç›‘å¬ç”¨æˆ·äº¤äº’äº‹ä»¶ï¼ˆç§»åŠ¨ç«¯éœ€è¦ï¼‰
    document.addEventListener('touchstart', handleUserInteraction, { once: true })
    document.addEventListener('click', handleUserInteraction, { once: true })
    
    return () => {
      document.removeEventListener('touchstart', handleUserInteraction)
      document.removeEventListener('click', handleUserInteraction)
    }
  }, [isAppReady, currentBGM])
  
  // ç›‘å¬å½•éŸ³å’Œè¯­éŸ³æ’­æ”¾çŠ¶æ€ï¼ŒåŠ¨æ€è°ƒæ•´éŸ³é‡
  useEffect(() => {
    if (!gainNodeRef.current || !isPlayingRef.current) return
    
    // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
    initAudioContext()
    const gainNode = gainNodeRef.current
    const audioContext = audioContextRef.current
    if (!audioContext) return
    
    const shouldLowerVolume = isRecording || isVoicePlaying
    const targetVolume = shouldLowerVolume ? LOW_VOLUME : FULL_VOLUME
    const currentTime = audioContext.currentTime
    
    // å¹³æ»‘è¿‡æ¸¡åˆ°ç›®æ ‡éŸ³é‡ï¼ˆ0.5ç§’è¿‡æ¸¡ï¼‰
    gainNode.gain.cancelScheduledValues(currentTime)
    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime)
    gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + 0.5)
    
    console.log(`ðŸŽµ BGMéŸ³é‡è°ƒæ•´: ${shouldLowerVolume ? 'é™ä½Žåˆ°30%' : 'æ¢å¤åˆ°100%'}`)
  }, [isRecording, isVoicePlaying])
  
  // æ¸…ç†å‡½æ•°
  const stopBGM = () => {
    if (sourceRef.current) {
      try {
        sourceRef.current.stop()
      } catch (e) {
        // å¿½ç•¥é”™è¯¯
      }
      sourceRef.current = null
    }
    isPlayingRef.current = false
  }
  
  return { currentBGM, stopBGM }
}

