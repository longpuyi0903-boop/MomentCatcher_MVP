import { useEffect, useRef, useState } from 'react'

/**
 * BGMç®¡ç†å™¨Hook
 * åŠŸèƒ½ï¼š
 * 1. éšæœºé€‰æ‹©å¹¶æ’­æ”¾BGM
 * 2. è‡ªåŠ¨å¾ªçŽ¯æ’­æ”¾
 * 3. éŸ³é‡æ·¡å…¥ï¼ˆ3ç§’ï¼‰
 * 4. å½•éŸ³/è¯­éŸ³æ’­æ”¾æ—¶éŸ³é‡é™åˆ°30%
 */
export const useBGM = (isAppReady, isRecording, isVoicePlaying) => {
  const audioContextRef = useRef(null)
  const gainNodeRef = useRef(null)
  const sourceRef = useRef(null)
  const audioBufferRef = useRef(null)
  const [currentBGM, setCurrentBGM] = useState(null)
  const isPlayingRef = useRef(false)
  const fadeInTimeoutRef = useRef(null)
  
  // BGMæ–‡ä»¶åˆ—è¡¨ï¼ˆéœ€è¦æ‰‹åŠ¨ç»´æŠ¤ï¼Œæ·»åŠ æ–°BGMæ—¶æ›´æ–°æ­¤åˆ—è¡¨ï¼‰
  const bgmFiles = [
    'Hans Zimmer - Interstellar - Main Theme (Piano Version)  Sheet Music.mp3'
    // åŽç»­æ·»åŠ æ›´å¤šBGMæ—¶ï¼Œåœ¨è¿™é‡Œæ·»åŠ æ–‡ä»¶å
  ]
  
  // éŸ³é‡å¸¸é‡
  const FULL_VOLUME = 0.6 // æ­£å¸¸éŸ³é‡ï¼ˆ60%ï¼‰
  const LOW_VOLUME = 0.18 // é™ä½ŽåŽçš„éŸ³é‡ï¼ˆ30% of 60%ï¼‰
  const FADE_IN_DURATION = 3000 // æ·¡å…¥æ—¶é•¿ï¼ˆ3ç§’ï¼‰
  
  // åˆå§‹åŒ–AudioContextï¼ˆå»¶è¿Ÿåˆ°éœ€è¦æ—¶åˆ›å»ºï¼Œé¿å…æµè§ˆå™¨é™åˆ¶ï¼‰
  const initAudioContext = () => {
    if (!audioContextRef.current) {
      try {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
        gainNodeRef.current = audioContextRef.current.createGain()
        gainNodeRef.current.connect(audioContextRef.current.destination)
        gainNodeRef.current.gain.value = 0 // åˆå§‹éŸ³é‡ä¸º0
        console.log('ðŸŽµ AudioContextåˆå§‹åŒ–æˆåŠŸ')
        
        // ã€æµ‹è¯•ä¼˜åŒ–ã€‘ç§»åŠ¨ç«¯ï¼šç«‹å³å°è¯•æ¢å¤AudioContextï¼ˆéœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
        if (audioContextRef.current.state === 'suspended') {
          // å°è¯•æ¢å¤ï¼ˆå¯èƒ½éœ€è¦ç”¨æˆ·äº¤äº’ï¼‰
          audioContextRef.current.resume().then(() => {
            console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¼˜åŒ–] AudioContextå·²æ¢å¤')
          }).catch(err => {
            console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¼˜åŒ–] AudioContextæ¢å¤å¤±è´¥ï¼Œéœ€è¦ç”¨æˆ·äº¤äº’:', err)
          })
        }
      } catch (error) {
        console.error('âŒ AudioContextåˆå§‹åŒ–å¤±è´¥:', error)
      }
    } else if (audioContextRef.current.state === 'suspended') {
      // å¦‚æžœAudioContextè¢«æš‚åœï¼Œå°è¯•æ¢å¤
      audioContextRef.current.resume().then(() => {
        console.log('ðŸŽµ AudioContextå·²æ¢å¤')
      }).catch(err => {
        console.warn('âš ï¸ AudioContextæ¢å¤å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç”¨æˆ·äº¤äº’:', err)
      })
    }
  }
  
  useEffect(() => {
    return () => {
      // æ¸…ç†èµ„æº
      if (fadeInTimeoutRef.current) {
        clearTimeout(fadeInTimeoutRef.current)
      }
      if (sourceRef.current) {
        try {
          sourceRef.current.stop()
        } catch (e) {
          // å¿½ç•¥é”™è¯¯
        }
        sourceRef.current = null
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
    }
  }, [])
  
  // éšæœºé€‰æ‹©BGM
  const selectRandomBGM = () => {
    if (bgmFiles.length === 0) return null
    const randomIndex = Math.floor(Math.random() * bgmFiles.length)
    // ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ŒViteä¼šè‡ªåŠ¨å¤„ç†publicç›®å½•
    return `/bgm/${bgmFiles[randomIndex]}`
  }
  
  // åŠ è½½å¹¶æ’­æ”¾BGM
  const loadAndPlayBGM = async (bgmPath) => {
    try {
      // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
      initAudioContext()
      const audioContext = audioContextRef.current
      if (!audioContext) {
        console.error('âŒ AudioContextæœªåˆå§‹åŒ–')
        return
      }
      
      // å¦‚æžœå·²ç»æœ‰éŸ³é¢‘åœ¨æ’­æ”¾ï¼Œå…ˆåœæ­¢
      if (sourceRef.current) {
        try {
          sourceRef.current.stop()
        } catch (e) {
          // å¿½ç•¥é”™è¯¯
        }
        sourceRef.current = null
      }
      
      // åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆURLç¼–ç å¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
      const encodedPath = encodeURI(bgmPath)
      console.log('ðŸŽµ åŠ è½½BGM:', encodedPath)
      const response = await fetch(encodedPath)
      if (!response.ok) {
        throw new Error(`BGMåŠ è½½å¤±è´¥: ${response.status} ${response.statusText}`)
      }
      const arrayBuffer = await response.arrayBuffer()
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer)
      audioBufferRef.current = audioBuffer
      
      // åˆ›å»ºéŸ³é¢‘æº
      const source = audioContext.createBufferSource()
      source.buffer = audioBuffer
      source.loop = true // å¾ªçŽ¯æ’­æ”¾
      source.connect(gainNodeRef.current)
      
      sourceRef.current = source
      
      // ã€ç§»åŠ¨ç«¯ä¿®å¤ã€‘ç¡®ä¿AudioContextåœ¨è¿è¡ŒçŠ¶æ€
      if (audioContext.state === 'suspended') {
        await audioContext.resume()
        console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] æ’­æ”¾å‰æ¢å¤AudioContext')
      }
      
      // å¼€å§‹æ’­æ”¾
      source.start(0)
      isPlayingRef.current = true
      
      // éŸ³é‡æ·¡å…¥
      const gainNode = gainNodeRef.current
      const currentTime = audioContext.currentTime
      const targetVolume = isRecording || isVoicePlaying ? LOW_VOLUME : FULL_VOLUME
      
      gainNode.gain.cancelScheduledValues(currentTime)
      gainNode.gain.setValueAtTime(0, currentTime)
      gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + FADE_IN_DURATION / 1000)
      
      console.log('ðŸŽµ BGMå¼€å§‹æ’­æ”¾:', bgmPath, 'AudioContextçŠ¶æ€:', audioContext.state, 'éŸ³é‡:', targetVolume)
    } catch (error) {
      console.error('âŒ BGMåŠ è½½å¤±è´¥:', error)
    }
  }
  
  // å½“åº”ç”¨å‡†å¤‡å°±ç»ªæ—¶ï¼Œéšæœºé€‰æ‹©BGMï¼ˆä½†ä¸ç«‹å³æ’­æ”¾ï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’ï¼‰
  useEffect(() => {
    if (isAppReady && !currentBGM && !isPlayingRef.current) {
      const bgmPath = selectRandomBGM()
      if (bgmPath) {
        setCurrentBGM(bgmPath)
        console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] BGMå·²é€‰æ‹©ï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’:', bgmPath)
        
        // ã€ç§»åŠ¨ç«¯ä¿®å¤ã€‘ç§»åŠ¨ç«¯ä¸è‡ªåŠ¨æ’­æ”¾ï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’
        // æ¡Œé¢ç«¯å¯ä»¥å°è¯•è‡ªåŠ¨æ’­æ”¾
        const isMobile = /Mobile|Android|iPhone|iPad/i.test(navigator.userAgent)
        if (!isMobile) {
          // æ¡Œé¢ç«¯ï¼šå»¶è¿Ÿä¸€ç‚¹åŽå°è¯•æ’­æ”¾
          setTimeout(() => {
            loadAndPlayBGM(bgmPath)
          }, 500)
        }
        // ç§»åŠ¨ç«¯ï¼šç­‰å¾…ç”¨æˆ·äº¤äº’ï¼ˆåœ¨handleUserInteractionä¸­æ’­æ”¾ï¼‰
      }
    }
  }, [isAppReady, currentBGM])
  
  // ã€ç§»åŠ¨ç«¯ä¿®å¤ã€‘ç›‘å¬ä»»ä½•ç”¨æˆ·äº¤äº’ï¼ˆä¸é™äºŽéº¦å…‹é£Žï¼‰ï¼Œæ¢å¤AudioContextå¹¶æ’­æ”¾BGM
  useEffect(() => {
    if (!isAppReady) return
    
    const handleUserInteraction = async () => {
      console.log('ðŸ‘† [ç§»åŠ¨ç«¯ä¿®å¤] æ£€æµ‹åˆ°ç”¨æˆ·äº¤äº’ï¼Œæ¢å¤AudioContextå¹¶æ’­æ”¾BGM')
      
      // åˆå§‹åŒ–AudioContextï¼ˆå¦‚æžœè¿˜æ²¡åˆå§‹åŒ–ï¼‰
      initAudioContext()
      
      // æ¢å¤AudioContextï¼ˆå¦‚æžœè¢«æš‚åœï¼‰
      if (audioContextRef.current) {
        if (audioContextRef.current.state === 'suspended') {
          try {
            await audioContextRef.current.resume()
            console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] AudioContextå·²æ¢å¤ï¼ŒçŠ¶æ€:', audioContextRef.current.state)
          } catch (err) {
            console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¿®å¤] æ¢å¤AudioContextå¤±è´¥:', err)
            return
          }
        }
        
        // ç¡®ä¿AudioContextåœ¨è¿è¡ŒçŠ¶æ€
        if (audioContextRef.current.state === 'running') {
          console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] AudioContextè¿è¡Œä¸­ï¼Œå°è¯•æ’­æ”¾BGM')
          // å¦‚æžœBGMè¿˜æ²¡æ’­æ”¾ï¼Œç«‹å³æ’­æ”¾
          if (!isPlayingRef.current) {
            if (currentBGM) {
              console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] ä½¿ç”¨å·²æœ‰BGM:', currentBGM)
              await loadAndPlayBGM(currentBGM)
            } else {
              // å¦‚æžœBGMè¿˜æ²¡é€‰æ‹©ï¼Œé€‰æ‹©å¹¶æ’­æ”¾
              const bgmPath = selectRandomBGM()
              if (bgmPath) {
                console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] é€‰æ‹©æ–°BGM:', bgmPath)
                setCurrentBGM(bgmPath)
                await loadAndPlayBGM(bgmPath)
              }
            }
          } else {
            console.log('ðŸŽµ [ç§»åŠ¨ç«¯ä¿®å¤] BGMå·²åœ¨æ’­æ”¾')
          }
        } else {
          console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¿®å¤] AudioContextçŠ¶æ€å¼‚å¸¸:', audioContextRef.current.state)
        }
      } else {
        console.warn('âš ï¸ [ç§»åŠ¨ç«¯ä¿®å¤] AudioContextæœªåˆå§‹åŒ–')
      }
    }
    
    // ã€ç§»åŠ¨ç«¯ä¿®å¤ã€‘ç›‘å¬æ‰€æœ‰ç”¨æˆ·äº¤äº’äº‹ä»¶ï¼ˆä¸é™åˆ¶æ¬¡æ•°ï¼Œç¡®ä¿BGMèƒ½æ’­æ”¾ï¼‰
    // ä½¿ç”¨captureé˜¶æ®µï¼Œç¡®ä¿èƒ½æ•èŽ·åˆ°æ‰€æœ‰äº¤äº’ï¼ˆåŒ…æ‹¬æŒ‰é’®ç‚¹å‡»ï¼‰
    document.addEventListener('touchstart', handleUserInteraction, { passive: true, capture: true })
    document.addEventListener('click', handleUserInteraction, { passive: true, capture: true })
    
    return () => {
      document.removeEventListener('touchstart', handleUserInteraction, { capture: true })
      document.removeEventListener('click', handleUserInteraction, { capture: true })
    }
  }, [isAppReady, currentBGM])
  
  // ç›‘å¬å½•éŸ³å’Œè¯­éŸ³æ’­æ”¾çŠ¶æ€ï¼ŒåŠ¨æ€è°ƒæ•´éŸ³é‡
  useEffect(() => {
    if (!gainNodeRef.current || !isPlayingRef.current) return
    
    // ç¡®ä¿AudioContextå·²åˆå§‹åŒ–
    initAudioContext()
    const gainNode = gainNodeRef.current
    const audioContext = audioContextRef.current
    if (!audioContext) return
    
    const shouldLowerVolume = isRecording || isVoicePlaying
    const targetVolume = shouldLowerVolume ? LOW_VOLUME : FULL_VOLUME
    const currentTime = audioContext.currentTime
    
    // å¹³æ»‘è¿‡æ¸¡åˆ°ç›®æ ‡éŸ³é‡ï¼ˆ0.5ç§’è¿‡æ¸¡ï¼‰
    gainNode.gain.cancelScheduledValues(currentTime)
    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime)
    gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + 0.5)
    
    console.log(`ðŸŽµ BGMéŸ³é‡è°ƒæ•´: ${shouldLowerVolume ? 'é™ä½Žåˆ°30%' : 'æ¢å¤åˆ°100%'}`)
  }, [isRecording, isVoicePlaying])
  
  // æ¸…ç†å‡½æ•°
  const stopBGM = () => {
    if (sourceRef.current) {
      try {
        sourceRef.current.stop()
      } catch (e) {
        // å¿½ç•¥é”™è¯¯
      }
      sourceRef.current = null
    }
    isPlayingRef.current = false
  }
  
  return { currentBGM, stopBGM }
}

