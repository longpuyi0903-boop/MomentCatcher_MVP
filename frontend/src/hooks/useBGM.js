import { useEffect, useRef, useState, useCallback } from 'react'

/**
 * BGMç®¡ç†å™¨Hook
 * åŠŸèƒ½ï¼š
 * 1. éšæœºé€‰æ‹©å¹¶æ’­æ”¾BGM
 * 2. è‡ªåŠ¨å¾ªç¯æ’­æ”¾
 * 3. éŸ³é‡æ·¡å…¥ï¼ˆ3ç§’ï¼‰
 * 4. å½•éŸ³/è¯­éŸ³æ’­æ”¾æ—¶éŸ³é‡é™åˆ°30%
 * 
 * ã€ç§»åŠ¨ç«¯ä¿®å¤ã€‘
 * - ä½¿ç”¨HTML Audioå…ƒç´ ä»£æ›¿Web Audio APIè¿›è¡Œæ’­æ”¾ï¼ˆæ›´å¥½çš„ç§»åŠ¨ç«¯å…¼å®¹æ€§ï¼‰
 * - Web Audio APIä»…ç”¨äºéŸ³é‡æ§åˆ¶
 * - é¢„åŠ è½½éŸ³é¢‘ï¼Œç”¨æˆ·äº¤äº’åç«‹å³æ’­æ”¾
 * 
 * ã€éŸ³é‡ä¿®å¤ã€‘
 * - Audioå…ƒç´ çš„volumeå¿…é¡»è®¾ä¸º1ï¼Œè®©Web Audio APIå®Œå…¨æ§åˆ¶éŸ³é‡
 * - æ‰€æœ‰éŸ³é‡æ§åˆ¶éƒ½é€šè¿‡GainNodeè¿›è¡Œ
 */
export const useBGM = (isAppReady, isRecording, isVoicePlaying) => {
  const audioElementRef = useRef(null) // HTML Audioå…ƒç´ ï¼ˆç”¨äºæ’­æ”¾ï¼‰
  const audioContextRef = useRef(null) // Web Audio APIï¼ˆä»…ç”¨äºéŸ³é‡æ§åˆ¶ï¼‰
  const gainNodeRef = useRef(null)
  const mediaSourceRef = useRef(null) // MediaElementAudioSourceNode
  const [currentBGM, setCurrentBGM] = useState(null)
  const isPlayingRef = useRef(false)
  const isInitializedRef = useRef(false) // æ˜¯å¦å·²åˆå§‹åŒ–
  const pendingPlayRef = useRef(false) // æ˜¯å¦æœ‰å¾…æ’­æ”¾çš„è¯·æ±‚
  const currentVolumeRef = useRef(0) // å½“å‰ç›®æ ‡éŸ³é‡ï¼ˆç”¨äºè¿½è¸ªï¼‰
  
  // BGMæ–‡ä»¶åˆ—è¡¨ï¼ˆéœ€è¦æ‰‹åŠ¨ç»´æŠ¤ï¼Œæ·»åŠ æ–°BGMæ—¶æ›´æ–°æ­¤åˆ—è¡¨ï¼‰
  const bgmFiles = [
    'Hans Zimmer - Interstellar - Main Theme (Piano Version)  Sheet Music.mp3'
    // åç»­æ·»åŠ æ›´å¤šBGMæ—¶ï¼Œåœ¨è¿™é‡Œæ·»åŠ æ–‡ä»¶å
  ]
  
  // éŸ³é‡å¸¸é‡
  const FULL_VOLUME = 0.6 // æ­£å¸¸éŸ³é‡ï¼ˆ60%ï¼‰
  const LOW_VOLUME = 0.18 // é™ä½åçš„éŸ³é‡ï¼ˆ30% of 60%ï¼‰
  const FADE_IN_DURATION = 3000 // æ·¡å…¥æ—¶é•¿ï¼ˆ3ç§’ï¼‰
  
  // éšæœºé€‰æ‹©BGM
  const selectRandomBGM = useCallback(() => {
    if (bgmFiles.length === 0) return null
    const randomIndex = Math.floor(Math.random() * bgmFiles.length)
    return `/bgm/${bgmFiles[randomIndex]}`
  }, [])
  
  // åˆå§‹åŒ–Audioå…ƒç´ å’ŒWeb Audio API
  const initAudio = useCallback(() => {
    if (isInitializedRef.current) return
    
    try {
      // åˆ›å»ºHTML Audioå…ƒç´ ï¼ˆç§»åŠ¨ç«¯å…¼å®¹æ€§æ›´å¥½ï¼‰
      if (!audioElementRef.current) {
        const audio = new Audio()
        audio.loop = true
        audio.preload = 'auto'
        // ã€éŸ³é‡ä¿®å¤ã€‘Audioå…ƒç´ çš„volumeå¿…é¡»è®¾ä¸º1
        // è®©Web Audio APIçš„GainNodeå®Œå…¨æ§åˆ¶éŸ³é‡
        audio.volume = 1
        audioElementRef.current = audio
        console.log('ğŸµ [éŸ³é‡ä¿®å¤] HTML Audioå…ƒç´ åˆ›å»ºæˆåŠŸï¼Œvolume=1')
      }
      
      // åˆ›å»ºWeb Audio APIï¼ˆç”¨äºç²¾ç»†éŸ³é‡æ§åˆ¶ï¼‰
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
        gainNodeRef.current = audioContextRef.current.createGain()
        gainNodeRef.current.connect(audioContextRef.current.destination)
        // ã€éŸ³é‡ä¿®å¤ã€‘GainNodeåˆå§‹éŸ³é‡ä¸º0ï¼Œæ·¡å…¥æ—¶ä¼šé€æ¸å¢åŠ 
        gainNodeRef.current.gain.value = 0
        currentVolumeRef.current = 0
        console.log('ğŸµ [éŸ³é‡ä¿®å¤] Web Audio APIåˆå§‹åŒ–æˆåŠŸï¼Œgain=0')
      }
      
      // è¿æ¥Audioå…ƒç´ åˆ°Web Audio APIï¼ˆåªè¿æ¥ä¸€æ¬¡ï¼‰
      if (!mediaSourceRef.current && audioElementRef.current && audioContextRef.current) {
        try {
          mediaSourceRef.current = audioContextRef.current.createMediaElementSource(audioElementRef.current)
          mediaSourceRef.current.connect(gainNodeRef.current)
          console.log('ğŸµ [éŸ³é‡ä¿®å¤] Audioå…ƒç´ å·²è¿æ¥åˆ°Web Audio API')
        } catch (err) {
          // å¦‚æœå·²ç»è¿æ¥è¿‡ï¼Œå¿½ç•¥é”™è¯¯
          console.warn('âš ï¸ [éŸ³é‡ä¿®å¤] Audioå…ƒç´ è¿æ¥è­¦å‘Šï¼ˆå¯èƒ½å·²è¿æ¥ï¼‰:', err.message)
        }
      }
      
      isInitializedRef.current = true
    } catch (error) {
      console.error('âŒ [éŸ³é‡ä¿®å¤] éŸ³é¢‘åˆå§‹åŒ–å¤±è´¥:', error)
    }
  }, [])
  
  // é¢„åŠ è½½BGM
  const preloadBGM = useCallback((bgmPath) => {
    if (!audioElementRef.current) {
      initAudio()
    }
    
    const encodedPath = encodeURI(bgmPath)
    console.log('ğŸµ [éŸ³é‡ä¿®å¤] é¢„åŠ è½½BGM:', encodedPath)
    
    audioElementRef.current.src = encodedPath
    audioElementRef.current.load()
    
    return new Promise((resolve, reject) => {
      const handleCanPlay = () => {
        console.log('ğŸµ [éŸ³é‡ä¿®å¤] BGMé¢„åŠ è½½å®Œæˆï¼Œå¯ä»¥æ’­æ”¾')
        audioElementRef.current.removeEventListener('canplaythrough', handleCanPlay)
        audioElementRef.current.removeEventListener('error', handleError)
        resolve()
      }
      
      const handleError = (e) => {
        console.error('âŒ [éŸ³é‡ä¿®å¤] BGMé¢„åŠ è½½å¤±è´¥:', e)
        audioElementRef.current.removeEventListener('canplaythrough', handleCanPlay)
        audioElementRef.current.removeEventListener('error', handleError)
        reject(e)
      }
      
      audioElementRef.current.addEventListener('canplaythrough', handleCanPlay, { once: true })
      audioElementRef.current.addEventListener('error', handleError, { once: true })
      
      // è¶…æ—¶å¤„ç†
      setTimeout(() => {
        audioElementRef.current.removeEventListener('canplaythrough', handleCanPlay)
        audioElementRef.current.removeEventListener('error', handleError)
        // å³ä½¿è¶…æ—¶ä¹Ÿå°è¯•æ’­æ”¾
        resolve()
      }, 10000)
    })
  }, [initAudio])
  
  // è®¾ç½®éŸ³é‡ï¼ˆç»Ÿä¸€çš„éŸ³é‡æ§åˆ¶å‡½æ•°ï¼‰
  const setVolume = useCallback((targetVolume, duration = 0.5) => {
    if (!gainNodeRef.current || !audioContextRef.current) {
      console.warn('âš ï¸ [éŸ³é‡ä¿®å¤] GainNodeæœªåˆå§‹åŒ–ï¼Œæ— æ³•è®¾ç½®éŸ³é‡')
      return
    }
    
    const gainNode = gainNodeRef.current
    const audioContext = audioContextRef.current
    
    // ç¡®ä¿AudioContextåœ¨è¿è¡Œ
    if (audioContext.state === 'suspended') {
      audioContext.resume()
    }
    
    const currentTime = audioContext.currentTime
    const currentGain = gainNode.gain.value
    
    // å–æ¶ˆä¹‹å‰çš„è°ƒåº¦
    gainNode.gain.cancelScheduledValues(currentTime)
    // ä»å½“å‰å€¼å¼€å§‹
    gainNode.gain.setValueAtTime(currentGain, currentTime)
    // å¹³æ»‘è¿‡æ¸¡åˆ°ç›®æ ‡éŸ³é‡
    gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + duration)
    
    currentVolumeRef.current = targetVolume
    console.log(`ğŸµ [éŸ³é‡ä¿®å¤] éŸ³é‡è°ƒæ•´: ${currentGain.toFixed(2)} -> ${targetVolume.toFixed(2)} (${duration}ç§’)`)
  }, [])
  
  // æ’­æ”¾BGMï¼ˆéœ€è¦åœ¨ç”¨æˆ·äº¤äº’åè°ƒç”¨ï¼‰
  const playBGM = useCallback(async () => {
    if (isPlayingRef.current) {
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] BGMå·²åœ¨æ’­æ”¾ä¸­')
      return
    }
    
    if (!audioElementRef.current) {
      console.warn('âš ï¸ [éŸ³é‡ä¿®å¤] Audioå…ƒç´ æœªåˆå§‹åŒ–')
      return
    }
    
    try {
      // æ¢å¤AudioContextï¼ˆç§»åŠ¨ç«¯å¿…éœ€ï¼‰
      if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume()
        console.log('ğŸµ [éŸ³é‡ä¿®å¤] AudioContextå·²æ¢å¤ï¼ŒçŠ¶æ€:', audioContextRef.current.state)
      }
      
      // ã€éŸ³é‡ä¿®å¤ã€‘ç¡®ä¿Audioå…ƒç´ çš„volumeæ˜¯1
      audioElementRef.current.volume = 1
      
      // è®¾ç½®åˆå§‹éŸ³é‡ä¸º0ï¼Œç„¶åæ·¡å…¥åˆ°ç›®æ ‡éŸ³é‡
      const gainNode = gainNodeRef.current
      const audioContext = audioContextRef.current
      
      if (gainNode && audioContext) {
        const currentTime = audioContext.currentTime
        // æ ¹æ®å½“å‰çŠ¶æ€å†³å®šç›®æ ‡éŸ³é‡
        const targetVolume = isRecording || isVoicePlaying ? LOW_VOLUME : FULL_VOLUME
        
        // ä»0å¼€å§‹æ·¡å…¥
        gainNode.gain.cancelScheduledValues(currentTime)
        gainNode.gain.setValueAtTime(0, currentTime)
        gainNode.gain.linearRampToValueAtTime(targetVolume, currentTime + FADE_IN_DURATION / 1000)
        
        currentVolumeRef.current = targetVolume
        console.log(`ğŸµ [éŸ³é‡ä¿®å¤] BGMæ·¡å…¥: 0 -> ${targetVolume} (${FADE_IN_DURATION/1000}ç§’)`)
      }
      
      // æ’­æ”¾éŸ³é¢‘
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] å¼€å§‹æ’­æ”¾BGM...')
      await audioElementRef.current.play()
      isPlayingRef.current = true
      pendingPlayRef.current = false
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] BGMæ’­æ”¾æˆåŠŸï¼')
    } catch (error) {
      console.error('âŒ [éŸ³é‡ä¿®å¤] BGMæ’­æ”¾å¤±è´¥:', error)
      // æ ‡è®°ä¸ºå¾…æ’­æ”¾ï¼Œç­‰å¾…ä¸‹æ¬¡ç”¨æˆ·äº¤äº’
      pendingPlayRef.current = true
    }
  }, [isRecording, isVoicePlaying, setVolume])
  
  // ç”¨æˆ·äº¤äº’å¤„ç†å‡½æ•°
  const handleUserInteraction = useCallback(async () => {
    console.log('ğŸ‘† [éŸ³é‡ä¿®å¤] æ£€æµ‹åˆ°ç”¨æˆ·äº¤äº’')
    
    // åˆå§‹åŒ–éŸ³é¢‘
    initAudio()
    
    // æ¢å¤AudioContext
    if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
      try {
        await audioContextRef.current.resume()
        console.log('ğŸµ [éŸ³é‡ä¿®å¤] AudioContextå·²æ¢å¤')
      } catch (err) {
        console.warn('âš ï¸ [éŸ³é‡ä¿®å¤] AudioContextæ¢å¤å¤±è´¥:', err)
      }
    }
    
    // å¦‚æœæœ‰å¾…æ’­æ”¾çš„BGMï¼Œç«‹å³æ’­æ”¾
    if (pendingPlayRef.current || (currentBGM && !isPlayingRef.current)) {
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] ç”¨æˆ·äº¤äº’åæ’­æ”¾BGM')
      await playBGM()
    }
  }, [initAudio, playBGM, currentBGM])
  
  // å½“åº”ç”¨å‡†å¤‡å°±ç»ªæ—¶ï¼Œåˆå§‹åŒ–å¹¶é¢„åŠ è½½BGM
  useEffect(() => {
    if (!isAppReady) return
    
    const setupBGM = async () => {
      // åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ
      initAudio()
      
      // é€‰æ‹©BGM
      if (!currentBGM) {
        const bgmPath = selectRandomBGM()
        if (bgmPath) {
          setCurrentBGM(bgmPath)
          console.log('ğŸµ [éŸ³é‡ä¿®å¤] BGMå·²é€‰æ‹©:', bgmPath)
          
          // é¢„åŠ è½½BGM
          try {
            await preloadBGM(bgmPath)
            pendingPlayRef.current = true // æ ‡è®°ä¸ºå¾…æ’­æ”¾
            
            // å°è¯•è‡ªåŠ¨æ’­æ”¾ï¼ˆæ¡Œé¢ç«¯å¯èƒ½æˆåŠŸï¼‰
            const isMobile = /Mobile|Android|iPhone|iPad/i.test(navigator.userAgent)
            if (!isMobile) {
              // æ¡Œé¢ç«¯å°è¯•è‡ªåŠ¨æ’­æ”¾
              setTimeout(() => {
                playBGM()
              }, 500)
            } else {
              console.log('ğŸµ [éŸ³é‡ä¿®å¤] ç§»åŠ¨ç«¯æ£€æµ‹åˆ°ï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’åæ’­æ”¾')
            }
          } catch (err) {
            console.error('âŒ BGMé¢„åŠ è½½å¤±è´¥:', err)
          }
        }
      } else if (pendingPlayRef.current) {
        // BGMå·²é€‰æ‹©ä½†æœªæ’­æ”¾ï¼Œå°è¯•æ’­æ”¾
        playBGM()
      }
    }
    
    setupBGM()
  }, [isAppReady, currentBGM, initAudio, selectRandomBGM, preloadBGM, playBGM])
  
  // ç›‘å¬ç”¨æˆ·äº¤äº’äº‹ä»¶ï¼ˆç”¨äºæ¢å¤AudioContextå’Œæ’­æ”¾BGMï¼‰
  useEffect(() => {
    if (!isAppReady) return
    
    // ç›‘å¬å¤šç§äº¤äº’äº‹ä»¶
    const events = ['touchstart', 'touchend', 'click', 'keydown', 'mousedown']
    
    events.forEach(event => {
      document.addEventListener(event, handleUserInteraction, { 
        passive: true, 
        capture: true 
      })
    })
    
    return () => {
      events.forEach(event => {
        document.removeEventListener(event, handleUserInteraction, { capture: true })
      })
    }
  }, [isAppReady, handleUserInteraction])
  
  // ã€éŸ³é‡ä¿®å¤ã€‘ç›‘å¬å½•éŸ³å’Œè¯­éŸ³æ’­æ”¾çŠ¶æ€ï¼ŒåŠ¨æ€è°ƒæ•´éŸ³é‡
  useEffect(() => {
    // åªæœ‰åœ¨BGMæ­£åœ¨æ’­æ”¾æ—¶æ‰è°ƒæ•´éŸ³é‡
    if (!isPlayingRef.current) {
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] BGMæœªåœ¨æ’­æ”¾ï¼Œè·³è¿‡éŸ³é‡è°ƒæ•´')
      return
    }
    
    if (!gainNodeRef.current || !audioContextRef.current) {
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] GainNodeæœªåˆå§‹åŒ–ï¼Œè·³è¿‡éŸ³é‡è°ƒæ•´')
      return
    }
    
    const shouldLowerVolume = isRecording || isVoicePlaying
    const targetVolume = shouldLowerVolume ? LOW_VOLUME : FULL_VOLUME
    
    // åªæœ‰å½“ç›®æ ‡éŸ³é‡ä¸å½“å‰ä¸åŒæ—¶æ‰è°ƒæ•´
    if (Math.abs(currentVolumeRef.current - targetVolume) < 0.01) {
      console.log('ğŸµ [éŸ³é‡ä¿®å¤] ç›®æ ‡éŸ³é‡ç›¸åŒï¼Œè·³è¿‡è°ƒæ•´')
      return
    }
    
    console.log(`ğŸµ [éŸ³é‡ä¿®å¤] çŠ¶æ€å˜åŒ– - isRecording: ${isRecording}, isVoicePlaying: ${isVoicePlaying}`)
    console.log(`ğŸµ [éŸ³é‡ä¿®å¤] éŸ³é‡è°ƒæ•´: ${shouldLowerVolume ? 'é™ä½åˆ°30%' : 'æ¢å¤åˆ°100%'} (${currentVolumeRef.current.toFixed(2)} -> ${targetVolume})`)
    
    setVolume(targetVolume, 0.5)
  }, [isRecording, isVoicePlaying, setVolume])
  
  // æ¸…ç†å‡½æ•°
  useEffect(() => {
    return () => {
      if (audioElementRef.current) {
        audioElementRef.current.pause()
        audioElementRef.current.src = ''
        audioElementRef.current = null
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }
      isPlayingRef.current = false
      isInitializedRef.current = false
    }
  }, [])
  
  // åœæ­¢BGM
  const stopBGM = useCallback(() => {
    if (audioElementRef.current) {
      audioElementRef.current.pause()
      audioElementRef.current.currentTime = 0
    }
    isPlayingRef.current = false
    console.log('ğŸµ BGMå·²åœæ­¢')
  }, [])
  
  return { currentBGM, stopBGM, playBGM }
}





