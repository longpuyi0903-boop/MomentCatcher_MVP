"""
Context RAG - ä¸Šä¸‹æ–‡æ£€ç´¢ï¼ˆV4 æ··åˆæ£€ç´¢ + Rerank ç‰ˆï¼‰

æ”¹è¿›ç‚¹ï¼š
1. SQLite ç»“æ„åŒ–æ£€ç´¢ï¼ˆV2ï¼‰
2. å‘é‡è¯­ä¹‰æ£€ç´¢ï¼ˆV3ï¼‰
3. LLM Query ç†è§£ï¼ˆV3ï¼‰
4. æ··åˆæ£€ç´¢ + ç»“æœèåˆï¼ˆV3ï¼‰
5. Rerank é‡æ’åºï¼ˆV4 æ–°å¢ï¼‰
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime

# å¯¼å…¥å­˜å‚¨å±‚
from .moment_storage import MomentStorage

# å¯¼å…¥å‘é‡å­˜å‚¨å±‚
try:
    from .vector_store import VectorStore
    VECTOR_AVAILABLE = True
except ImportError:
    VECTOR_AVAILABLE = False

# å¯¼å…¥æŸ¥è¯¢è§£æå™¨
try:
    from .query_parser import QueryParser, get_query_parser
    QUERY_PARSER_AVAILABLE = True
except ImportError:
    QUERY_PARSER_AVAILABLE = False

# å¯¼å…¥ Reranker
try:
    from .reranker import Reranker, get_reranker
    RERANKER_AVAILABLE = True
except ImportError:
    RERANKER_AVAILABLE = False


class ContextRAG:
    """
    ä¸Šä¸‹æ–‡æ£€ç´¢ç³»ç»Ÿï¼ˆV4 æ··åˆæ£€ç´¢ + Rerankï¼‰
    
    ç‰¹æ€§ï¼š
    1. ç»“æ„åŒ–æ£€ç´¢ï¼ˆSQLite å®ä½“ç´¢å¼•ï¼‰
    2. å‘é‡æ£€ç´¢ï¼ˆChromaDB è¯­ä¹‰åŒ¹é…ï¼‰
    3. LLM Query ç†è§£ï¼ˆæ™ºèƒ½è§£ææŸ¥è¯¢æ„å›¾ï¼‰
    4. æ··åˆæ£€ç´¢ + ç»“æœèåˆ
    5. Rerank é‡æ’åº
    """
    
    def __init__(self, user_id: str = None, base_moments_dir: str = "storage", 
                 enable_rerank: bool = True):
        """
        åˆå§‹åŒ– Context RAG
        
        Args:
            user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
            base_moments_dir: Moments åŸºç¡€ç›®å½•
            enable_rerank: æ˜¯å¦å¯ç”¨ Rerank
        """
        self.user_id = user_id or "default_user"
        self.base_moments_dir = Path(base_moments_dir)
        self.enable_rerank = enable_rerank
        
        # SQLite å­˜å‚¨
        self.storage = MomentStorage(
            user_id=self.user_id,
            base_dir=str(self.base_moments_dir)
        )
        
        # å‘é‡å­˜å‚¨
        if VECTOR_AVAILABLE:
            self.vector_store = VectorStore(
                user_id=self.user_id,
                base_dir=str(self.base_moments_dir)
            )
        else:
            self.vector_store = None
        
        # æŸ¥è¯¢è§£æå™¨
        if QUERY_PARSER_AVAILABLE:
            self.query_parser = get_query_parser()
        else:
            self.query_parser = None
        
        # Reranker
        if RERANKER_AVAILABLE and enable_rerank:
            self.reranker = get_reranker()
        else:
            self.reranker = None
        
        # å…¼å®¹æ—§ä»£ç 
        self.moments_dir = self.base_moments_dir / "moments" / self.user_id
        
        print(f"ğŸ” ContextRAG V4 åˆå§‹åŒ–: user={self.user_id}")
        print(f"   ç»“æ„åŒ–æ£€ç´¢: âœ…")
        print(f"   å‘é‡æ£€ç´¢: {'âœ…' if self.vector_store else 'âŒ'}")
        print(f"   Query è§£æ: {'âœ…' if self.query_parser else 'âŒ'}")
        print(f"   Rerank: {'âœ…' if self.reranker else 'âŒ'}")
    
    def set_user_id(self, user_name: str, agent_name: str):
        """è®¾ç½®ç”¨æˆ· ID"""
        self.user_id = f"{user_name}_{agent_name}".replace(" ", "_")
        self.storage.set_user_id(user_name, agent_name)
        
        if self.vector_store:
            self.vector_store.set_user_id(user_name, agent_name)
        
        self.moments_dir = self.base_moments_dir / "moments" / self.user_id
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢ï¼ˆä¸»å…¥å£ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›æ•°é‡
            
        Returns:
            List[Dict]: æ£€ç´¢ç»“æœ
        """
        print(f"\nğŸ” æ··åˆæ£€ç´¢: '{query}'")
        
        # 1. è§£ææŸ¥è¯¢
        if self.query_parser:
            search_config = self.query_parser.get_search_config(query)
            print(f"   ğŸ“Š æ£€ç´¢é…ç½®: strategy={search_config.get('use_structured', True)}/{search_config.get('use_vector', True)}")
            print(f"   ğŸ“Š å…³é”®è¯: {search_config.get('keywords', [])}")
            print(f"   ğŸ“Š æ‰©å±•æŸ¥è¯¢: {search_config.get('expanded_queries', [])}")
        else:
            # é™çº§é…ç½®
            search_config = {
                "use_structured": True,
                "use_vector": True,
                "structured_weight": 0.5,
                "vector_weight": 0.5,
                "keywords": self._extract_keywords_simple(query),
                "entity_types": ["objects", "places", "people", "events"],
                "expanded_queries": [query]
            }
        
        results = []
        
        # 2. ç»“æ„åŒ–æ£€ç´¢
        if search_config.get("use_structured", True):
            structured_results = self._search_structured(
                keywords=search_config.get("keywords", []),
                entity_types=search_config.get("entity_types", []),
                top_k=top_k
            )
            print(f"   ğŸ“¦ ç»“æ„åŒ–æ£€ç´¢: {len(structured_results)} æ¡")
            
            # åŠ æƒ
            weight = search_config.get("structured_weight", 0.5)
            for r in structured_results:
                r["source"] = "structured"
                r["weighted_score"] = r.get("score", 0) * weight
            results.extend(structured_results)
        
        # 3. å‘é‡æ£€ç´¢
        if search_config.get("use_vector", True) and self.vector_store:
            # ä½¿ç”¨æ‰©å±•æŸ¥è¯¢
            expanded_queries = search_config.get("expanded_queries", [query])
            vector_results = []
            
            for eq in expanded_queries[:2]:  # æœ€å¤šç”¨2ä¸ªæ‰©å±•æŸ¥è¯¢
                vr = self.vector_store.search(eq, top_k=top_k)
                vector_results.extend(vr)
            
            print(f"   ğŸ”® å‘é‡æ£€ç´¢: {len(vector_results)} æ¡")
            
            # åŠ æƒ
            weight = search_config.get("vector_weight", 0.5)
            for r in vector_results:
                r["source"] = "vector"
                r["weighted_score"] = r.get("score", 0) * weight
            results.extend(vector_results)
        
        # 4. ç»“æœèåˆ + å»é‡
        merged = self._merge_results(results, top_k * 2)  # å¤šå–ä¸€äº›ç»™ Rerank
        print(f"   âœ… èåˆå: {len(merged)} æ¡")
        
        # 5. åŠ è½½å®Œæ•´ Moment æ•°æ®
        final_results = []
        seen_ids = set()
        
        for r in merged:
            moment_id = r.get("moment_id", "")
            if moment_id and moment_id not in seen_ids:
                moment = self.storage.get_moment(moment_id)
                if moment:
                    moment["retrieval_score"] = r.get("weighted_score", 0)
                    moment["retrieval_source"] = r.get("source", "unknown")
                    final_results.append(moment)
                    seen_ids.add(moment_id)
        
        # 6. Rerank é‡æ’åº
        if self.reranker and len(final_results) > 1:
            print(f"   ğŸ”„ Rerank é‡æ’åº...")
            final_results = self.reranker.rerank(query, final_results, top_k=top_k)
        
        return final_results[:top_k]
    
    def _search_structured(self, keywords: List[str], 
                           entity_types: List[str], 
                           top_k: int = 5) -> List[Dict]:
        """ç»“æ„åŒ–æ£€ç´¢"""
        results = []
        
        for kw in keywords[:5]:  # æœ€å¤š5ä¸ªå…³é”®è¯
            # æŒ‰å®ä½“ç±»å‹æ£€ç´¢
            for et in entity_types:
                matches = self.storage.search_by_entity(et, kw, top_k=3)
                for m in matches:
                    results.append({
                        "moment_id": m["moment_id"],
                        "score": 1.0,  # ç²¾ç¡®åŒ¹é…ç»™æ»¡åˆ†
                        "match_type": f"{et}:{kw}"
                    })
            
            # å…³é”®è¯æ£€ç´¢
            kw_matches = self.storage.search_by_keywords([kw], top_k=3)
            for m in kw_matches:
                results.append({
                    "moment_id": m["moment_id"],
                    "score": 0.8,
                    "match_type": f"keyword:{kw}"
                })
        
        return results
    
    def _merge_results(self, results: List[Dict], top_k: int) -> List[Dict]:
        """
        ç»“æœèåˆï¼ˆæŒ‰ moment_id èšåˆåˆ†æ•°ï¼‰
        """
        # æŒ‰ moment_id èšåˆ
        score_map = {}
        
        for r in results:
            mid = r.get("moment_id", "")
            if not mid:
                continue
            
            if mid not in score_map:
                score_map[mid] = {
                    "moment_id": mid,
                    "weighted_score": 0,
                    "sources": [],
                    "match_types": []
                }
            
            score_map[mid]["weighted_score"] += r.get("weighted_score", 0)
            score_map[mid]["sources"].append(r.get("source", ""))
            if "match_type" in r:
                score_map[mid]["match_types"].append(r["match_type"])
        
        # æ’åº
        merged = list(score_map.values())
        merged.sort(key=lambda x: x["weighted_score"], reverse=True)
        
        # æ ‡è®°æ¥æº
        for m in merged:
            sources = set(m["sources"])
            if "structured" in sources and "vector" in sources:
                m["source"] = "hybrid"
            elif "structured" in sources:
                m["source"] = "structured"
            else:
                m["source"] = "vector"
        
        return merged[:top_k]
    
    def _extract_keywords_simple(self, text: str) -> List[str]:
        """ç®€å•å…³é”®è¯æå–ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'å—', 'å‘¢', 'å•Š', 'å§',
                     'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'è®°å¾—', 'è¿˜', 'æœ‰', 'æ²¡æœ‰', 'é‚£ä¸ª', 'è¿™ä¸ª'}
        
        keywords = []
        
        # ç®€å•åˆ†è¯
        for i in range(len(text) - 1):
            bigram = text[i:i+2]
            if bigram not in stopwords:
                keywords.append(bigram)
        
        return list(set(keywords))[:10]
    
    # ============================================================
    # å…¼å®¹æ—§ API
    # ============================================================
    
    def search_by_keywords(self, keywords: List[str], top_k: int = 3) -> List[Dict]:
        """åŸºäºå…³é”®è¯æ£€ç´¢ï¼ˆå…¼å®¹æ—§ APIï¼‰"""
        return self.storage.search_by_keywords(keywords, top_k)
    
    def search_by_content(self, query: str, top_k: int = 3) -> List[Dict]:
        """åŸºäºå†…å®¹æ£€ç´¢ï¼ˆå…¼å®¹æ—§ APIï¼Œç°åœ¨ä½¿ç”¨æ··åˆæ£€ç´¢ï¼‰"""
        return self.search(query, top_k)
    
    def get_recent_moments(self, n: int = 5) -> List[Dict]:
        """è·å–æœ€è¿‘çš„ n ä¸ª Moments"""
        return self.storage.get_recent_moments(n)
    
    def search_by_emotion(self, emotion: str, top_k: int = 3) -> List[Dict]:
        """åŸºäºæƒ…ç»ªæ£€ç´¢"""
        all_moments = self.storage.get_all_moments()
        results = [m for m in all_moments if m.get('emotion_tag') == emotion]
        return results[:top_k]
    
    def is_fact_query(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åœ¨é—®äº‹å®"""
        if self.query_parser:
            parsed = self.query_parser.parse(query)
            return parsed.get("query_type") == "fact"
        
        # é™çº§è§„åˆ™
        fact_patterns = [
            r'(ä»€ä¹ˆ|å•¥)(é¢œè‰²|å£å‘³|å‘³é“|é…è‰²|åå­—)',
            r'(è®°å¾—|è®°ä¸è®°å¾—).*(å—|å˜›)',
            r'(å“ª|å“ªé‡Œ|å“ªå„¿|åœ¨å“ª)',
            r'(å‡ ç‚¹|ä»€ä¹ˆæ—¶å€™|å¤šä¹…)',
            r'(è°|æ˜¯è°)',
            r'(å¤šå°‘|å‡ ä¸ª|å‡ æ¬¡)',
        ]
        return any(re.search(p, query) for p in fact_patterns)
    
    def generate_context_prompt(self, query: str, max_context: int = 2) -> str:
        """
        ç”Ÿæˆä¸Šä¸‹æ–‡æç¤ºï¼ˆç”¨äºæ³¨å…¥åˆ° LLM promptï¼‰
        
        Args:
            query: å½“å‰æŸ¥è¯¢
            max_context: æœ€å¤šåŒ…å«å‡ ä¸ª Moments çš„ä¸Šä¸‹æ–‡
        
        Returns:
            str: ä¸Šä¸‹æ–‡æç¤ºæ–‡æœ¬
        """
        # åˆ¤æ–­æ˜¯å¦åœ¨é—®äº‹å®
        is_asking_fact = self.is_fact_query(query)
        
        if is_asking_fact:
            print(f"ğŸ” æ£€æµ‹åˆ°äº‹å®æŸ¥è¯¢: {query}")
            
            # æ··åˆæ£€ç´¢
            results = self.search(query, top_k=max_context)
            
            if results:
                # æ‰¾åˆ°ç»“æœ
                best_result = results[0]
                fact = self._extract_fact_from_moment(best_result, query)
                
                if fact:
                    print(f"   âœ… æ‰¾åˆ°äº‹å®: {fact[:100]}...")
                    return self._build_fact_prompt_high_confidence(
                        fact,
                        self._get_moment_context(best_result)
                    )
            
            # æ²¡æ‰¾åˆ°
            print(f"   âŒ æœªæ‰¾åˆ°ç›¸å…³äº‹å®")
            return self._build_fact_prompt_not_found()
        
        # æ™®é€šå¯¹è¯æ£€ç´¢
        relevant_moments = self.search(query, top_k=max_context)
        
        if not relevant_moments:
            return ""
        
        print(f"   âœ… æ‰¾åˆ° {len(relevant_moments)} ä¸ªç›¸å…³ Moments")
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "ã€é‡è¦ï¼šå†å²è®°å¿†ã€‘\nä½ å’Œç”¨æˆ·ä¹‹å‰èŠè¿‡ä»¥ä¸‹å†…å®¹ï¼š\n\n"
        
        for i, moment in enumerate(relevant_moments, 1):
            timestamp = moment.get('timestamp', '')
            if timestamp:
                dt = datetime.fromisoformat(timestamp)
                time_str = dt.strftime('%Yå¹´%mæœˆ%dæ—¥')
            else:
                time_str = "ä¹‹å‰"
            
            context += f"ğŸ“Œ {time_str}çš„å¯¹è¯ï¼š\n"
            
            # æ¥æºæ ‡è®°
            source = moment.get('retrieval_source', 'unknown')
            if source == 'hybrid':
                context += f"[ç²¾ç¡®+è¯­ä¹‰åŒ¹é…]\n"
            elif source == 'vector':
                context += f"[è¯­ä¹‰åŒ¹é…]\n"
            
            if moment.get('summary'):
                context += f"æ‘˜è¦ï¼š{moment['summary']}\n"
            
            messages = moment.get('messages', [])
            if messages:
                for msg in messages[:6]:
                    role = "ç”¨æˆ·" if msg['role'] == 'user' else "ä½ "
                    content = msg['content'][:80]
                    context += f"  {role}ï¼š{content}\n"
            
            context += "\n"
        
        context += self._get_memory_rules()
        return context.strip()
    
    def _extract_fact_from_moment(self, moment: Dict, query: str) -> Optional[str]:
        """ä» Moment ä¸­æå–äº‹å®"""
        entities = moment.get('entities', {})
        
        # å°è¯•ä»å®ä½“ä¸­æå–
        if "é¢œè‰²" in query or "é…è‰²" in query:
            for obj_name, obj_info in entities.get('objects', {}).items():
                if obj_info.get('color') or obj_info.get('description'):
                    return obj_info.get('description') or obj_info.get('color')
        
        if "å£å‘³" in query or "å‘³é“" in query:
            for obj_name, obj_info in entities.get('objects', {}).items():
                if 'å’–å•¡' in obj_name or 'æ‹¿é“' in obj_name or 'èŒ¶' in obj_name:
                    return obj_info.get('description') or obj_name
        
        # ä»æ¶ˆæ¯ä¸­æå–
        user_messages = [m['content'] for m in moment.get('messages', []) if m['role'] == 'user']
        if user_messages:
            return " ".join(user_messages[:2])
        
        return None
    
    def _get_moment_context(self, moment: Dict) -> str:
        """è·å– Moment çš„å®Œæ•´ä¸Šä¸‹æ–‡"""
        parts = []
        
        if moment.get('summary'):
            parts.append(f"æ‘˜è¦ï¼š{moment['summary']}")
        
        messages = moment.get('messages', [])
        for msg in messages[:4]:
            role = "ç”¨æˆ·" if msg['role'] == 'user' else "Agent"
            parts.append(f"{role}ï¼š{msg['content']}")
        
        return "\n".join(parts)
    
    def _build_fact_prompt_high_confidence(self, fact: str, full_context: str) -> str:
        """æ„å»ºé«˜ç½®ä¿¡åº¦äº‹å®çš„ prompt"""
        return f"""
ã€âš ï¸ æå…¶é‡è¦ï¼šä½ å¿…é¡»å‡†ç¡®å›ç­”è¿™ä¸ªäº‹å®ï¼Œç¦æ­¢ç¼–é€ ã€‘

ç”¨æˆ·åœ¨è¯¢é—®ä¸€ä¸ªå…·ä½“äº‹å®ã€‚æˆ‘å·²ç»ä»å†å²å¯¹è¯ä¸­æ‰¾åˆ°äº†å‡†ç¡®ç­”æ¡ˆï¼š

âœ… **æ‰¾åˆ°çš„äº‹å®**ï¼š
{fact}

âœ… **å®Œæ•´ä¸Šä¸‹æ–‡**ï¼š
{full_context}

âš ï¸ **è§„åˆ™**ï¼š
1. å¿…é¡»ä½¿ç”¨ä¸Šé¢çš„äº‹å®å›ç­”
2. ç¦æ­¢ç¼–é€ æˆ–ä¿®æ”¹
3. å¯ä»¥åŠ è¯­æ°”è¯è®©å›ç­”è‡ªç„¶
"""
    
    def _build_fact_prompt_not_found(self) -> str:
        """æ„å»ºæœªæ‰¾åˆ°äº‹å®çš„ prompt"""
        return """
ã€ğŸš¨ æœ€é«˜ä¼˜å…ˆçº§ï¼šä½ ä¸è®°å¾—è¿™ä¸ªç»†èŠ‚ï¼Œå¿…é¡»æ‰¿è®¤ï¼Œç¦æ­¢ç¼–é€ ã€‘

ç”¨æˆ·åœ¨è¯¢é—®ä¸€ä¸ªå…·ä½“äº‹å®ï¼Œä½†æˆ‘åœ¨å†å²è®°å¿†ä¸­æ‰¾ä¸åˆ°ç›¸å…³ä¿¡æ¯ã€‚

ä½ å¿…é¡»æ‰¿è®¤ä¸è®°å¾—ï¼š
- âœ… "è¿™ä¸ªæˆ‘å¥½åƒæ²¡å¬ä½ æè¿‡ï¼Œæ˜¯ä»€ä¹ˆï¼Ÿ"
- âœ… "æˆ‘è®°ä¸å¤ªæ¸…äº†ï¼Œä½ èƒ½æé†’æˆ‘ä¸€ä¸‹å—ï¼Ÿ"

ç»å¯¹ç¦æ­¢ç¼–é€ ä»»ä½•å†…å®¹ï¼
"""
    
    def _get_memory_rules(self) -> str:
        """è¿”å›è®°å¿†è§„åˆ™æç¤º"""
        return """
âš ï¸ **è®°å¿†è§„åˆ™**ï¼š
- æœ‰æ˜ç¡®äº‹å®æ—¶å¿…é¡»å‡†ç¡®ä½¿ç”¨ï¼Œä¸èƒ½ä¿®æ”¹
- ä¸ç¡®å®šæ—¶æ‰¿è®¤ä¸è®°å¾—ï¼Œç¦æ­¢ç¼–é€ 
- ç¦æ­¢ç”¨æ¨¡ç³Šè¡¨è¾¾é€ƒé¿äº‹å®
"""


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================

def test_context_rag():
    """æµ‹è¯• Context RAG V3"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯• Context RAG V3 (æ··åˆæ£€ç´¢)")
    print("="*60 + "\n")
    
    rag = ContextRAG(base_moments_dir="storage/test")
    
    # æµ‹è¯•æ··åˆæ£€ç´¢
    test_queries = [
        "å’–å•¡ä»€ä¹ˆå£å‘³",
        "è¢«è¡¨æ‰¬çš„äº‹",
        "å·¥ä½œä¸Šå¼€å¿ƒçš„äº‹",
        "æ–¹æ¡ˆçš„é…è‰²"
    ]
    
    for query in test_queries:
        print(f"\n{'='*40}")
        results = rag.search(query, top_k=2)
        print(f"   ç»“æœæ•°: {len(results)}")
        for r in results:
            print(f"   ğŸ“Œ {r.get('moment_id')}: score={r.get('retrieval_score', 0):.2f}, source={r.get('retrieval_source')}")
    
    # æµ‹è¯•ç”Ÿæˆä¸Šä¸‹æ–‡
    print(f"\n{'='*40}")
    print("ğŸ“ æµ‹è¯•ç”Ÿæˆä¸Šä¸‹æ–‡")
    context = rag.generate_context_prompt("ä½ è®°å¾—æˆ‘æ–¹æ¡ˆçš„é…è‰²å—", max_context=2)
    print(f"   ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
    print(f"   é¢„è§ˆ: {context[:200]}...")
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60 + "\n")


if __name__ == "__main__":
    test_context_rag()
